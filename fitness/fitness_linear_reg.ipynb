{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e933e47d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully.\n",
      "\n",
      "--- Initial Data Quality Check ---\n",
      "Total samples: 20000, Total features: 44\n",
      "Total null values found: 0\n",
      "Total duplicated rows found: 0\n",
      "\n",
      "Feature Engineering complete: 'Training_Volume' and 'Calorie_Density' created.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import make_scorer, mean_absolute_error\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from statsmodels.tools.tools import add_constant\n",
    "# --- 1. Data Loading and Quality Checks ---\n",
    "df = pd.read_csv(\"expanded_fitness_data.csv\")\n",
    "print(\"Data loaded successfully.\")\n",
    "print(\"\\n--- Initial Data Quality Check ---\")\n",
    "print(f\"Total samples: {df.shape[0]}, Total features: {df.shape[1]}\")\n",
    "print(f\"Total null values found: {df.isnull().sum().sum()}\")\n",
    "print(f\"Total duplicated rows found: {df.duplicated().sum()}\")\n",
    "\n",
    "# --- 2. Feature Engineering ---\n",
    "# Training Volume = Sets * Reps (Measure of total work)\n",
    "df['Training_Volume'] = df['Sets'] * df['Reps']\n",
    "# Calorie Density = Calories / serving_size_g (Measure of food quality)\n",
    "epsilon = 1e-6\n",
    "df['Calorie_Density'] = df['Calories'] / (df['serving_size_g'] + epsilon)\n",
    "print(\"\\nFeature Engineering complete: 'Training_Volume' and 'Calorie_Density' created.\")\n",
    "# --- 3. Define Final Feature Set (VIF-Treated) and Target ---\n",
    "# This set reflects the stability treatment: Weight (kg) and BMI were removed due to high VIF.\n",
    "# Training_Volume is included as an engineered feature.\n",
    "final_features = [\n",
    "    'Session_Duration (hours)', 'Avg_BPM', 'Max_BPM', 'Resting_BPM',\n",
    "    'Height (m)', 'Age', 'Fat_Percentage', 'Experience_Level', \n",
    "    'Workout_Frequency (days/week)', 'Training_Volume', \n",
    "    'Workout_Type' # Categorical feature\n",
    "]\n",
    "X = df[final_features]\n",
    "y = df['Calories_Burned']\n",
    "# --- 4. Encoding and Final Data Preparation (Pipeline) ---\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "# Define numeric and categorical feature lists\n",
    "numeric_features = [f for f in final_features if f != 'Workout_Type']\n",
    "categorical_features = ['Workout_Type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b8feeac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final VIF Check (showing top 10) ---\n",
      "| feature                       | VIF     |\n",
      "|:------------------------------|:--------|\n",
      "| Experience_Level              | 4.66198 |\n",
      "| Workout_Frequency (days/week) | 3.35366 |\n",
      "| Session_Duration (hours)      | 2.36458 |\n",
      "| Workout_Type_Strength         | 1.5162  |\n",
      "| Workout_Type_Yoga             | 1.51448 |\n",
      "| Workout_Type_HIIT             | 1.51128 |\n",
      "| Fat_Percentage                | 1.03534 |\n",
      "| Height (m)                    | 1.02778 |\n",
      "| Max_BPM                       | 1.0153  |\n",
      "| Training_Volume               | 1.0113  |\n"
     ]
    }
   ],
   "source": [
    "# ColumnTransformer: median imputation + scaling for numeric, one-hot for categorical\n",
    "# Build OneHotEncoder in a version-compatible way (sparse vs sparse_output)\n",
    "try:\n",
    "    ohe = OneHotEncoder(drop='first', sparse=False, handle_unknown='ignore')\n",
    "except TypeError:\n",
    "    # newer sklearn renamed 'sparse' to 'sparse_output'\n",
    "    ohe = OneHotEncoder(drop='first', sparse_output=False, handle_unknown='ignore')\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', Pipeline(steps=[('imputer', SimpleImputer(strategy='median')), ('scaler', StandardScaler())]), numeric_features),\n",
    "    ('cat', ohe, categorical_features),\n",
    "], remainder='drop')\n",
    "\n",
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor), ('regressor', LinearRegression())])\n",
    "\n",
    "# Fit preprocessor separately to build a DataFrame for diagnostics (VIF) and to get feature names\n",
    "X_processed = preprocessor.fit_transform(X)\n",
    "num_cols = numeric_features\n",
    "# get OHE feature names in a way that works across sklearn versions\n",
    "try:\n",
    "    cat_cols = preprocessor.named_transformers_['cat'].get_feature_names_out(categorical_features).tolist()\n",
    "except Exception:\n",
    "    # fallback for older sklearn versions\n",
    "    try:\n",
    "        cat_cols = preprocessor.named_transformers_['cat'].get_feature_names(categorical_features).tolist()\n",
    "    except Exception:\n",
    "        # last resort: infer based on transformed shape\n",
    "        cat_cols = [f\"{categorical_features[0]}_lvl_{i}\" for i in range(X_processed.shape[1] - len(num_cols))]\n",
    "\n",
    "feature_names = num_cols + cat_cols\n",
    "X_encoded_clean = pd.DataFrame(X_processed, columns=feature_names)\n",
    "# replace infs and -infs with NaN\n",
    "X_encoded_clean.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "# show missing counts after preprocessing\n",
    "nan_counts = X_encoded_clean.isnull().sum()\n",
    "if nan_counts.any():\n",
    "    print(\"Missing values per column after preprocessing (will fill with median for VIF):\")\n",
    "    print(nan_counts[nan_counts > 0])\n",
    "# fill feature NaNs with column median (safe for VIF and linear model)\n",
    "X_encoded_clean = X_encoded_clean.fillna(X_encoded_clean.median())\n",
    "# ensure target is numeric and align indexes\n",
    "y_clean = pd.to_numeric(y, errors='coerce')\n",
    "if y_clean.isnull().any():\n",
    "    print(f\"Warning: {y_clean.isnull().sum()} target rows could not be coerced to numeric and will be dropped.\")\n",
    "mask = y_clean.notnull()\n",
    "X_encoded_clean = X_encoded_clean.loc[mask].reset_index(drop=True)\n",
    "y_clean = y_clean.loc[mask].reset_index(drop=True)\n",
    "# also keep the original X filtered for pipeline cross-val/training\n",
    "X_filtered = X.loc[mask].reset_index(drop=True)\n",
    "# add constant and compute VIF (handle exceptions per-column)\n",
    "X_vif_check = add_constant(X_encoded_clean)\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data[\"feature\"] = X_vif_check.columns\n",
    "vifs = []\n",
    "for i in range(X_vif_check.shape[1]):\n",
    "    try:\n",
    "        vifs.append(variance_inflation_factor(X_vif_check.values, i))\n",
    "    except Exception as e:\n",
    "        vifs.append(np.nan)\n",
    "        print(f\"VIF computation failed for column index {i} ({X_vif_check.columns[i]}): {e}\")\n",
    "vif_data[\"VIF\"] = vifs\n",
    "vif_data = vif_data[vif_data['feature'] != 'const'].sort_values(by=\"VIF\", ascending=False)\n",
    "print(\"\\n--- Final VIF Check (showing top 10) ---\")\n",
    "print(vif_data.head(10).to_markdown(index=False, numalign=\"left\", stralign=\"left\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b0b51dcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=======================================================\n",
      "  FINAL CROSS-VALIDATION RESULTS (Pipeline Linear Regression)  \n",
      "=======================================================\n",
      "Target Variable: Calories_Burned\n",
      "Model Type: sklearn Pipeline -> Linear Regression\n",
      "-------------------------------------------------------\n",
      "Mean R-squared (Consistency): 0.9677 (+/- 0.0011)\n",
      "Mean Absolute Error (Accuracy): 59.64 calories (+/- 1.50)\n",
      "=======================================================\n",
      "\n",
      "--- Top 5 Feature Contributions (Coefficients) ---\n",
      "|                          | Coefficient   |\n",
      "|:-------------------------|:--------------|\n",
      "| Workout_Type_HIIT        | 451.314       |\n",
      "| Session_Duration (hours) | 339.464       |\n",
      "| Workout_Type_Yoga        | 297.73        |\n",
      "| Workout_Type_Strength    | 151.466       |\n",
      "| Experience_Level         | 91.3004       |\n"
     ]
    }
   ],
   "source": [
    "# --- 6. Cross-Validation (Model Training and Evaluation) using Pipeline ---\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "mae_scorer = make_scorer(mean_absolute_error, greater_is_better=False)\n",
    "\n",
    "# 5-Fold Cross-Validation for R-squared and MAE using the pipeline and the original filtered X\n",
    "r2_scores = cross_val_score(pipeline, X_filtered, y_clean, scoring='r2', cv=cv)\n",
    "mae_scores = -cross_val_score(pipeline, X_filtered, y_clean, scoring=mae_scorer, cv=cv)\n",
    "\n",
    "# --- 7. Display Final Best Results and Coefficients ---\n",
    "print(\"\\n=======================================================\")\n",
    "print(\"  FINAL CROSS-VALIDATION RESULTS (Pipeline Linear Regression)  \")\n",
    "print(\"=======================================================\")\n",
    "print(f\"Target Variable: Calories_Burned\")\n",
    "print(f\"Model Type: sklearn Pipeline -> Linear Regression\")\n",
    "print(\"-\" * 55)\n",
    "print(f\"Mean R-squared (Consistency): {np.mean(r2_scores):.4f} (+/- {np.std(r2_scores):.4f})\")\n",
    "print(f\"Mean Absolute Error (Accuracy): {np.mean(mae_scores):.2f} calories (+/- {np.std(mae_scores):.2f})\")\n",
    "print(\"=======================================================\")\n",
    "\n",
    "# Train the final pipeline on all filtered data to get the final coefficients\n",
    "pipeline.fit(X_filtered, y_clean)\n",
    "# Extract linear coefficients by transforming X_filtered through preprocessor\n",
    "X_all_processed = preprocessor.transform(X_filtered)\n",
    "coeffs = pipeline.named_steps['regressor'].coef_\n",
    "coefficients = pd.DataFrame(coeffs, feature_names, columns=['Coefficient'])\n",
    "coefficients_sorted = coefficients.abs().sort_values(by='Coefficient', ascending=False)\n",
    "\n",
    "print(\"\\n--- Top 5 Feature Contributions (Coefficients) ---\")\n",
    "print(coefficients_sorted.head(5).to_markdown(numalign=\"left\", stralign=\"left\"))\n",
    "# ...existing code..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9221fcc7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
